# Pr√°ctica 3

**Autores:**  
- Laura Herrera Negr√≠n  
- Ayman Asbai Ghoudan

**Universidad:** Universidad de Las Palmas de Gran Canaria  
**Asignatura:** Visi√≥n por Computador  

---
## Contenidos
- [Librer√≠as utilizadas](#librerias)
- [Tarea 1 - Conteo de monedas)](#tarea1)
- [Tarea 2 - Identificaci√≥n de micropl√°sticos](#tarea2)
---

<a name= "librerias"></a>
## Librer√≠as utilizadas

[![NumPy](https://img.shields.io/badge/NumPy-%23013243?style=for-the-badge&logo=numpy&logoColor=white)](https://numpy.org/)  
- Manipulaci√≥n eficiente de arreglos y matrices.  
- C√°lculos estad√≠sticos y vectoriales sobre las caracter√≠sticas extra√≠das.  
- Operaciones matem√°ticas para medir distancias entre vectores de caracter√≠sticas.  

 [![Matplotlib](https://img.shields.io/badge/Matplotlib-%23006DBA?style=for-the-badge&logo=matplotlib&logoColor=white)](https://matplotlib.org/)  
- Visualizaci√≥n de resultados de clasificaci√≥n (im√°genes reales vs predichas).  
- Presentaci√≥n de comparativas gr√°ficas y figuras informativas.  

[![Seaborn](https://img.shields.io/badge/Seaborn-%232E8B57?style=for-the-badge&logo=seaborn&logoColor=white)](https://seaborn.pydata.org/)  
- Visualizaci√≥n avanzada de datos.  
- Creaci√≥n de la **matriz de confusi√≥n** mediante mapas de calor con estilo mejorado.  

[![scikit-learn](https://img.shields.io/badge/scikit--learn-%23F7931E?style=for-the-badge&logo=scikitlearn&logoColor=white)](https://scikit-learn.org/stable/)  
- Evaluaci√≥n del rendimiento del clasificador (exactitud, precisi√≥n, recall, F1-score).  
- Normalizaci√≥n de vectores de caracter√≠sticas con `StandardScaler`.  
- Generaci√≥n y an√°lisis de la matriz de confusi√≥n.  

[![CSV](https://img.shields.io/badge/CSV-%2300BFAE?style=for-the-badge&logo=csv&logoColor=white)](https://docs.python.org/3/library/csv.html)  
- Lectura y manejo de anotaciones desde archivos CSV.  
- Carga de etiquetas reales y coordenadas de bounding boxes para validar la clasificaci√≥n.  

--- 
<a name="tarea1"></a>
## TAREA 1: Los ejemplos ilustrativos anteriores permiten saber el n√∫mero de monedas presentes en la imagen. ¬øC√≥mo saber la cantidad de dinero presente en ella? Sugerimos identificar de forma interactiva (por ejemplo haciendo clic en la imagen) una moneda de un valor determinado en la imagen (por ejemplo de 1‚Ç¨). Tras obtener esa informaci√≥n y las dimensiones en mil√≠metros de las distintas monedas, realiza una propuesta para estimar la cantidad de dinero en la imagen. Muestra la cuenta de monedasW y dinero sobre la imagen. No hay restricciones sobre utilizar medidas geom√©tricas o de color. 



---
<a name="tarea2"></a>
## TAREA 2: La tarea consiste en extraer caracter√≠sticas (geom√©tricas y/o visuales) de las tres im√°genes completas de partida, y *aprender* patrones que permitan identificar las part√≠culas en nuevas im√°genes. Para ello se proporciona como imagen de test *MPs_test.jpg* y sus correpondientes anotaciones *MPs_test_bbs.csv* con la que deben obtener las m√©tricas para su propuesta de clasificaci√≥n de micropl√°sticos, adem√°s de la matriz de confusi√≥n. La matriz de confusi√≥n permitir√° mostrar para cada clase el n√∫mero de muestras que se clasifican correctamente de dicha clase, y el n√∫mero de muestras que se clasifican incorrectamente como perteneciente a una de las otras dos clases.

En el trabajo [SMACC: A System for Microplastics Automatic Counting and Classification](https://doi.org/10.1109/ACCESS.2020.2970498), las caracter√≠sticas geom√©tricas utilizadas fueron:

- √Årea en p√≠xeles
- Per√≠metro en p√≠xeles
- Compacidad (relaci√≥n entre el cuadrado del per√≠metro y el √°rea de la part√≠cula)
- Relaci√≥n del √°rea de la part√≠cula con la del contenedor
- Relaci√≥n del ancho y el alto del contenedor
- Relaci√≥n entre los ejes de la elipse ajustada
- Definido el centroide, relaci√≥n entre las distancias menor y mayor al contorno

Esta tarea implementa un **sistema de clasificaci√≥n de micropl√°sticos** en im√°genes, utilizando t√©cnicas de **visi√≥n por computador**. A partir de im√°genes de referencia, el sistema **extrae caracter√≠sticas geom√©tricas y de color** de cada part√≠cula, entrena un clasificador simple basado en distancia euclidiana ponderada, y eval√∫a su rendimiento en una imagen de prueba con anotaciones.

### ‚öôÔ∏è Funciones principales

A continuaci√≥n se describen las principales funciones implementadas para llevar a cabo este proceso:
```py 
detectar_caracteristicas(contorno, imagen_hsv)
```
Extrae un conjunto de **caracter√≠sticas geom√©tricas y de color** a partir de un contorno detectado:  
- √Årea, per√≠metro, compacidad, excentricidad.  
- Relaciones de forma (ancho/alto, √°rea relativa, distancias al centroide).  
- Estad√≠sticas del color en HSV (media y desviaci√≥n).

---

```py 
extraer_caracteristicas_imagen(imagen_path)
```
Procesa una imagen completa:  
- Convierte a escala de grises.  
- Aplica desenfoque y umbral adaptativo para separar objetos del fondo.  
- Encuentra contornos y calcula sus caracter√≠sticas con la funci√≥n anterior.

---

```py
vector_caracteristicas_medio(imagen_path)
```
- Obtiene el **vector medio de caracter√≠sticas** de todos los objetos de una imagen.
- Se usa para representar cada clase (tipo de micropl√°stico) de forma promedio.

---

```py
entrenar_clasificador(imagenes_referencia)
```
- Calcula el vector de caracter√≠sticas medio para cada clase (por ejemplo, FRA, PEL, TAR) usando im√°genes de referencia. Estos ser√°n la **base del clasificador**.

---

```py 
preparar_referencias(mean_vectors)
```
- Normaliza los vectores de referencia con `StandardScaler` y define un **vector de pesos** que ajusta la importancia de cada caracter√≠stica (por ejemplo, m√°s peso al color o a la forma).  

La normalizaci√≥n es importante porque las caracter√≠sticas pueden tener escalas muy diferentes (por ejemplo, el √°rea puede tener valores miles de veces mayores que la compacidad o el color), lo que har√≠a que unas dominen sobre otras al calcular distancias o similitudes. 
Al usar `StandardScaler`, todas las caracter√≠sticas se transforman para tener **media cero** y **varianza unitaria**, garantizando que ninguna domine sobre las dem√°s.
Luego, los pesos permiten dar m√°s relevancia a las caracter√≠sticas m√°s discriminativas seg√∫n el contexto, logrando comparaciones m√°s justas y representativas.

---

```py 
clasificar_contorno(...)
```
- Dada una regi√≥n de inter√©s (bounding box), calcula las caracter√≠sticas del contorno y las compara con las referencias.
- Clasifica el objeto seg√∫n la **distancia euclidiana ponderada m√°s corta**.

---

```py 
clasificar_imagen_con_anotaciones(...)
```
Procesa una imagen completa y sus anotaciones (desde un CSV):  
- Detecta contornos.  
- Clasifica cada objeto dentro de las regiones anotadas.  
- Devuelve las etiquetas reales y predichas junto con la imagen combinada para visualizaci√≥n.  

---

```py 
mostrar_resultado_visual(y_true, y_pred, imagen_combined)
```
- Muestra visualmente los resultados de clasificaci√≥n (reales vs predichos) y calcula la precisi√≥n global del modelo.

![Resultado visual](salidas/comparacion_real_predicha.jpg)

Tal y como se observa en la imagen, la parte izquierda muestra la clasificaci√≥n real (seg√∫n las anotaciones del archivo CSV) y la parte derecha muestra la clasificaci√≥n predicha por el modelo.

Cada tipo de micropl√°stico est√° representado con un color diferente:
* üü• Fragmentos (FRA): contornos y etiquetas en rojo.
* üü© Pellets (PEL): contornos y etiquetas en verde.
* üü¶ Alquitr√°n (TAR): contornos y etiquetas en azul.

De esta forma, es posible comparar visualmente de un vistazo las predicciones y los aciertos.
En general, la mayor√≠a de los objetos coinciden correctamente entre ambas im√°genes, aunque se aprecian algunas discrepancias: 
- Algunos fragmentos rojos fueron clasificados err√≥neamente como pellets verdes, lo que coincide con la confusi√≥n detectada en la matriz de confusi√≥n.
- Las part√≠culas de alquitr√°n azul suelen estar correctamente clasificadas, aunque en ciertos casos con forma irregular o bordes difusos el modelo las confundi√≥ con fragmentos.
- La distribuci√≥n general de colores muestra una buena correspondencia global entre las clasificaciones reales y las predichas, lo que respalda el resultado cuantitativo obtenido (accuracy ‚âà 72 %).

---
```py 
mostrar_matriz_confusion(y_true, y_pred, clases)
```
- Genera un **heatmap de la matriz de confusi√≥n** con Seaborn para visualizar los aciertos y errores del clasificador.  

La matriz de confusi√≥n obtenida es: 
![Matriz de confusi√≥n](salidas/matriz_confusion.jpg)

La **matriz de confusi√≥n** muestra, para cada clase real, c√≥mo el clasificador asign√≥ las predicciones.  
Cada fila representa las **etiquetas reales**, y cada columna las **etiquetas predichas**.

Interpretaci√≥n:
- **Diagonal principal (37, 24, 9):** son los aciertos del modelo ‚Üí el objeto se clasific√≥ correctamente.  
- **Fuera de la diagonal:** representan errores de clasificaci√≥n (confusiones entre clases).  

#### üîç An√°lisis detallado:
- La clase **FRA** (fragmentos) tuvo **37 aciertos**, pero fue confundida **7 veces con PEL** (pellets) y **3 veces con TAR** (tiras).  
  Esto sugiere que algunos fragmentos comparten **formas o colores similares a los pellets**, lo que genera confusi√≥n.
  
- La clase **PEL** tuvo un rendimiento s√≥lido (**24 aciertos**, 7 errores hacia FRA).  
  Nuevamente, la mayor confusi√≥n se da entre **FRA ‚Üî PEL**, lo que indica que ambas clases tienen **caracter√≠sticas geom√©tricas o crom√°ticas parecidas**.

- La clase **TAR** obtuvo **9 aciertos**, pero tambi√©n se confundi√≥ en **3 casos como FRA** y **2 como PEL**.  
  Al ser posiblemente m√°s oscura o de forma irregular, puede haberse interpretado err√≥neamente seg√∫n la iluminaci√≥n o textura.

En conjunto, el **patr√≥n de confusi√≥n dominante** es entre **fragmentos (FRA)** y **pellets (PEL)**, lo que sugiere que el modelo podr√≠a beneficiarse de:
- Aumentar el peso de las caracter√≠sticas **de color** (HSV).  
- A√±adir m√°s im√°genes de entrenamiento para ambos tipos.  
- Aplicar segmentaci√≥n m√°s precisa para evitar que fragmentos incompletos afecten el c√°lculo de caracter√≠sticas.  

Sin embargo, se intent√≥ cambiar el peso de las distintas caracter√≠sticas pero, el resultado obtenido era peor que este pues, a la vez que mejoraba un elemento en concreto, los otros dos empeoraban.

---

```py 
imprimir_metricas(y_true, y_pred)
```
Esta funci√≥n calcula las m√©tricas del clasificador:
| M√©trica | Descripci√≥n | Valor (%) |
|----------|--------------|-------|
| **Exactitud (Accuracy)** | Porcentaje total de clasificaciones correctas sobre todas las predicciones. | 72.16|
| **Precisi√≥n** | Qu√© tan precisas son las predicciones positivas (por clase). Indica el nivel de ‚Äúfalsos positivos‚Äù cometidos. | 75.25|
| **Sensibilidad (Recall)** | Mide la capacidad del modelo para detectar correctamente todos los objetos de una clase (minimiza los falsos negativos). | 72.16|
| **F1-Score** | Promedio arm√≥nico entre precisi√≥n y recall; balance entre exactitud y cobertura. | 73.67|

### üìà Interpretaci√≥n de las m√©tricas:
- El modelo logra un rendimiento moderado-alto, identificando correctamente alrededor del 72 % de los micropl√°sticos.
- La precisi√≥n del 75 % indica que la mayor√≠a de las predicciones son correctas, mientras que un recall similar muestra que el sistema detecta bien las clases, aunque a√∫n pierde algunos objetos.
- El F1-score de 73.67 % refleja un equilibrio adecuado entre precisi√≥n y cobertura.

En conjunto, los resultados son satisfactorios considerando la simplicidad del clasificador y la variabilidad visual de las muestras.
