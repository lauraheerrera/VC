# Pr√°ctica 3

**Autores:**  
- Laura Herrera Negr√≠n  
- Ayman Asbai Ghoudan

**Universidad:** Universidad de Las Palmas de Gran Canaria  
**Asignatura:** Visi√≥n por Computador  

---
## Contenidos
- [Librer√≠as utilizadas](#librerias)
- [Tarea 1 - Conteo de monedas](#tarea1)
- [Tarea 2 - Identificaci√≥n de micropl√°sticos](#tarea2)
---

<a name= "librerias"></a>
## Librer√≠as utilizadas

[![NumPy](https://img.shields.io/badge/NumPy-%23013243?style=for-the-badge&logo=numpy&logoColor=white)](https://numpy.org/)  
- Manipulaci√≥n eficiente de arreglos y matrices.  
- C√°lculos estad√≠sticos y vectoriales sobre las caracter√≠sticas extra√≠das.  
- Operaciones matem√°ticas para medir distancias entre vectores de caracter√≠sticas.  

 [![Matplotlib](https://img.shields.io/badge/Matplotlib-%23006DBA?style=for-the-badge&logo=matplotlib&logoColor=white)](https://matplotlib.org/)  
- Visualizaci√≥n de resultados de clasificaci√≥n (im√°genes reales vs predichas).  
- Presentaci√≥n de comparativas gr√°ficas y figuras informativas.  

[![Seaborn](https://img.shields.io/badge/Seaborn-%232E8B57?style=for-the-badge&logo=seaborn&logoColor=white)](https://seaborn.pydata.org/)  
- Visualizaci√≥n avanzada de datos.  
- Creaci√≥n de la **matriz de confusi√≥n** mediante mapas de calor con estilo mejorado.  

[![scikit-learn](https://img.shields.io/badge/scikit--learn-%23F7931E?style=for-the-badge&logo=scikitlearn&logoColor=white)](https://scikit-learn.org/stable/)  
- Evaluaci√≥n del rendimiento del clasificador (exactitud, precisi√≥n, recall, F1-score).  
- Normalizaci√≥n de vectores de caracter√≠sticas con `StandardScaler`.  
- Generaci√≥n y an√°lisis de la matriz de confusi√≥n.  

[![CSV](https://img.shields.io/badge/CSV-%2300BFAE?style=for-the-badge&logo=csv&logoColor=white)](https://docs.python.org/3/library/csv.html)  
- Lectura y manejo de anotaciones desde archivos CSV.  
- Carga de etiquetas reales y coordenadas de bounding boxes para validar la clasificaci√≥n.  

--- 
<a name="tarea1"></a>
## TAREA 1 
**Los ejemplos ilustrativos anteriores permiten saber el n√∫mero de monedas presentes en la imagen. ¬øC√≥mo saber la cantidad de dinero presente en ella? Sugerimos identificar de forma interactiva (por ejemplo haciendo clic en la imagen) una moneda de un valor determinado en la imagen (por ejemplo de 1‚Ç¨). Tras obtener esa informaci√≥n y las dimensiones en mil√≠metros de las distintas monedas, realiza una propuesta para estimar la cantidad de dinero en la imagen. Muestra la cuenta de monedasW y dinero sobre la imagen. No hay restricciones sobre utilizar medidas geom√©tricas o de color.**
- **Salida:**
  - [`salidas/monedas_ideal_resultado.jpg`](salidas/monedas_ideal_resultado.jpg)
  - [`salidas/Monedas1_resultado.jpg`](salidas/Monedas1_resultado.jpg)
  - [`salidas/monedas2_resultado.jpg`](salidas/monedas2_resultado.jpg)
  - [`salidas/monedas3_resultado.jpg`](salidas/monedas3_resultado.jpg)

Esta tarea tiene como principal objetivo detectar monedas en una imagen y estimar la cantidad total de dinero presente. Para ello, se ha seguido la sugerencia planteada: el programa permite al usuario **seleccionar interactivamente una moneda de referencia** (haciendo clic en ella) e indicar su **valor en euros**.
Con esta informaci√≥n y las dimensiones reales de monedas en mil√≠metros, se calcula la **escala mil√≠metro - p√≠xel** y se determina el valor de todas las monedas detectadas en la imagen. 

El resultado final mostrar√°:
* Las monedas detectadas
* El valor estimado de cada moneda
* El total dinero presente en la imagen


### ‚öôÔ∏è Funciones principales

A continuaci√≥n se describen las principales funciones implementadas para llevar a cabo este proceso:
```py 
cargar_y_preprocesar(ruta_img, metodo='gris')
```
- Carga la imagen desde disco y aplica un preprocesamiento para mejorar la detecci√≥n:
  - Si se usa el m√©todo `gris`, convierte a escala de grises y aplica un desenfoque mediano.
  - Si se usa `threshold`, convierte a gris y aplica binarizaci√≥n con Otsu para segmentar las monedas.
---
```py 
detectar_monedas(img, metodo='hough', radio_min=40, radio_max=160, area_min=200)
```
- Detecta las monedas presentes en la imagen:
 - Con `metodo=hough`, usa **Transformada de Hough** para detectar c√≠rculos.
 - Con `metodo=contours`, usa **contornos y c√≠rculos m√≠nimos envolventes.**
Cada moneda detectada se almacena con su centro y su radio en p√≠xeles.
---
```py 
seleccionar_moneda_referencia(img, monedas)
```
- Permite al usuario hacer **clic sobre una moneda** en la imagen para seleccionarla como **referencia**.
- Guarda sus coordenadas y radio, que se usar√°n para **calcular la escala**.
---
```py 
calcular_escala(ref_moneda)
```
- Solicita al usuario el valor de la moneda seleccionada (por ejemplo, 1‚Ç¨ o 0.10‚Ç¨) y calcula la **escala miol√≠metro - p√≠xel**, comparando el radio detectado con el radio real de esa moneda.
- Esta escala se usar√° para estimar el tama√±o de las dem√°s monedas.
---
```py 
clasificar_monedas(monedas, escala, rel_tol=0.12, abs_tol_mm=1.5)
```
- Convierte el radio de cada moneda de p√≠xeles a mil√≠metros y lo compara con los radios reales de las monedas de euro.
- Asigna a cada moneda el valor m√°s probable (0.01‚Ç¨, 0.02‚Ç¨, 0.05‚Ç¨, 0.10‚Ç¨, 0.20‚Ç¨, 0.50‚Ç¨, 1‚Ç¨, 2‚Ç¨) y calcula el total acumulado.
---
```py 
crear_rellenos(img, monedas)
```
- Genera una imagen en blanco y negro donde las monedas detectadas aparecen como c√≠rculos blancos rellenos.
---
```py 
mostrar_resultados(img, img_rellenos, resultados, total, ruta_salida)
```
Muestra los resultados de forma visual:
- Imagen original.
- Imagen de rellenos.
- Imagen final con monedas detectadas, su valor y el total.
Asimismo, guarda la imagen final con las monedas y sus valores en la ruta indicada: `salidas/..._resultado.jpg`
---
```py 
contar_monedas(ruta_img, metodo='hough')
```
Integra todas las funciones anteriores:
1. Carga y preprocesa la imagen.
2. Detecta las monedas.
3. Permite seleccionar la moneda de referencia.
4. Calcula la escala y clasifica las monedas.
5. Muestra y guarda los resultados finales.
Devuelve el total detectado y una lista de los resultados individuales.
---

El programa implementa dos m√©todos para adaptarse a distintos tipos de im√°genes:
| **M√©todo** | **Descripci√≥n** | **Ventajas** | **Inconvenientes** |
|--------------|------------------|--------------|----------------|
| **`threshold/contours`** | Segmenta la imagen mediante binarizaci√≥n (umbral) y detecta contornos circulares. | Ideal para im√°genes limpias o sint√©ticas (‚Äúimagen ideal‚Äù). | En im√°genes reales con sombras o brillos, puede fallar o detectar menos monedas. |
| **`hough`** | Utiliza la Transformada de Hough para detectar c√≠rculos directamente sobre la imagen en escala de grises. | M√°s robusto ante variaciones de iluminaci√≥n o fondos complejos. | En im√°genes ideales, puede dar errores en el c√°lculo de los valores de las monedas. |

Ya que no se ha sido capaz de obtener buenos resultados para ambas situaciones, se ha desarrollado una versi√≥n con ambos m√©todos:
- En la imagen ideal, el m√©todo por umbral `(threshold/contours)` ofrece mejores resultados.
- En im√°genes reales o no ideales, el m√©todo de Hough detecta mejor las monedas.

#### üîç Resultados obtenidos

**Imagen ideal**

En esta situaci√≥n, se trabaja con un entorno ideal, donde las condiciones son √≥ptimas para la detecci√≥n de monedas. Una **imagen ideal** se caracteriza por:
- Iluminaci√≥n uniforme, sin sombras ni reflejos.
- Fondo liso y homog√©neo, que contrasta claramente con las monedas.
- Monedas bien separadas, sin solapamientos ni oclusiones.
- Enfoque n√≠tido y sin ruido, lo que facilita la detecci√≥n de bordes y contornos circulares.
- Escala constante y sin deformaciones de perspectiva.

Gracias a estas condiciones, la detecci√≥n mediante el m√©todo de **umbral y contornos** resulta precisa, permitiendo identificar correctamente el n√∫mero y el valor de las monedas presentes, independientemente de la moneda de referencia seleccionada.

Esto ocurre porque la relaci√≥n entre los radios de las monedas y los reales, al no existir distorsiones, se mantienen constantes y proporcionales.

<div align="center">
  <img src="salidas/monedas_ideal_resultado.jpg" width="50%">
</div>

**Imagen no ideal**

<a name="ejemplo1"></a>
_Ejemplo 1_
<div align="center">
  <img src="salidas/Monedas1_resultado.jpg" width="75%">
</div>

<a name="ejemplo2"></a>
_Ejemplo 2_
<div align="center">
  <img src="salidas/monedas2_resultado.jpg" width="75%">
</div>

<a name="ejemplo3"></a>
_Ejemplo 3_
<div align="center">
  <img src="salidas/monedas3_resultado.jpg" width="75%">
</div>

En las anteriores situacciones, se ha trabajado con im√°genes **no ideales**, donde las condiciones son m√°s complejas y no garantizan una detecci√≥n perfecta, como en la imagen ideal.
Algunas caracter√≠sticas de las im√°genes no ideales son:
- Iluminaci√≥n irregular, con sombras y reflejos que dificultan la segmentaci√≥n.
- Distorsiones de perspectiva, que alteran la proporci√≥n entre el radio detectado y el real.
- Objetos que no son monedas presentes en la escena, aumentando la probabilidad de falsos positivos.

Como resultado, algunas monedas no se detectan correctamente. Por ejemplo, en el [Ejemplo 1](#ejemplo1), monedas de 1‚Ç¨ pueden detectarse √∫nicamente por la parte plateada, mientras que la parte dorada no se reconoce.

Asimismo, algunos valores **no se reconocen correctamente** debido a peque√±as variaciones en el tama√±o detectado de las monedas o al solapamiento parcial con otras monedas u objetos. Esto puede provocar que algunas monedas sean clasificadas err√≥neamente, hecho que ocurre en todos los ejemplos. 

[V√©ase:  [Ejemplo 1](#ejemplo1),  [Ejemplo 2](#ejemplo2),  [Ejemplo 3](#ejemplo3) ]

Asimismo, algunos valores **no se reconocen correctamente** debido a peque√±as variaciones en el tama√±o detectado de las monedas o al solapamiento parcial con otras monedas u objetos. Esto puede provocar que monedas de 0.10‚Ç¨, 0.20‚Ç¨ o 0.50‚Ç¨ sean clasificadas err√≥neamente o marcadas como ‚Äúno confiables‚Äù.


Adem√°s, el **valor detectado** puede depender de la **moneda de referencia seleccionada**, pues las proporciones reales entre radios se ven afectadas por sombras o deformaciones, lo que provoca variaciones en la estimaci√≥n final.

Tal y como se coment√≥ anteriormente, el m√©todo de **HoughCircles** resulta m√°s robusto frente a variaciones de iluminaci√≥n o fondos complejos

---
<a name="tarea2"></a>
## TAREA 2: La tarea consiste en extraer caracter√≠sticas (geom√©tricas y/o visuales) de las tres im√°genes completas de partida, y *aprender* patrones que permitan identificar las part√≠culas en nuevas im√°genes. 
- **Salida:**
  - [`salidas/comparacion_real_predicha.jpg`](salidas/comparacion_real_predicha.jpg)
  - [`salidas/matriz_confusion.jpg`](salidas/matriz_confusion.jpg)

Esta tarea implementa un **sistema de clasificaci√≥n de micropl√°sticos** en im√°genes, utilizando t√©cnicas de **visi√≥n por computador**. A partir de im√°genes de referencia, el sistema **extrae caracter√≠sticas geom√©tricas y de color** de cada part√≠cula, entrena un clasificador simple basado en distancia euclidiana ponderada, y eval√∫a su rendimiento en una imagen de prueba con anotaciones.

### ‚öôÔ∏è Funciones principales

A continuaci√≥n se describen las principales funciones implementadas para llevar a cabo este proceso:
```py 
detectar_caracteristicas(contorno, imagen_hsv)
```
Extrae un conjunto de **caracter√≠sticas geom√©tricas y de color** a partir de un contorno detectado:  
- √Årea, per√≠metro, compacidad, excentricidad.  
- Relaciones de forma (ancho/alto, √°rea relativa, distancias al centroide).  
- Estad√≠sticas del color en HSV (media y desviaci√≥n).
---

```py 
extraer_caracteristicas_imagen(imagen_path)
```
Procesa una imagen completa:  
- Convierte a escala de grises.  
- Aplica desenfoque y umbral adaptativo para separar objetos del fondo.  
- Encuentra contornos y calcula sus caracter√≠sticas con la funci√≥n anterior.
---

```py
vector_caracteristicas_medio(imagen_path)
```
- Obtiene el **vector medio de caracter√≠sticas** de todos los objetos de una imagen.
- Se usa para representar cada clase (tipo de micropl√°stico) de forma promedio.
---

```py
entrenar_clasificador(imagenes_referencia)
```
- Calcula el vector de caracter√≠sticas medio para cada clase (por ejemplo, FRA, PEL, TAR) usando im√°genes de referencia. Estos ser√°n la **base del clasificador**.
---

```py 
preparar_referencias(mean_vectors)
```
- Normaliza los vectores de referencia con `StandardScaler` y define un **vector de pesos** que ajusta la importancia de cada caracter√≠stica (por ejemplo, m√°s peso al color o a la forma).  

La normalizaci√≥n es importante porque las caracter√≠sticas pueden tener escalas muy diferentes (por ejemplo, el √°rea puede tener valores miles de veces mayores que la compacidad o el color), lo que har√≠a que unas dominen sobre otras al calcular distancias o similitudes. 
Al usar `StandardScaler`, todas las caracter√≠sticas se transforman para tener **media cero** y **varianza unitaria**, garantizando que ninguna domine sobre las dem√°s.
Luego, los pesos permiten dar m√°s relevancia a las caracter√≠sticas m√°s discriminativas seg√∫n el contexto, logrando comparaciones m√°s justas y representativas.

---

```py 
clasificar_contorno(...)
```
- Dada una regi√≥n de inter√©s (bounding box), calcula las caracter√≠sticas del contorno y las compara con las referencias.
- Clasifica el objeto seg√∫n la **distancia euclidiana ponderada m√°s corta**.
---

```py 
clasificar_imagen_con_anotaciones(...)
```
Procesa una imagen completa y sus anotaciones (desde un CSV):  
- Carga la imagen de test (`MPs_test.jpg`) y sus anotaciones (`MPs_test_bbs.csv`).
- Detecta los contornos y clasifica cada uno de los objetos dentro de las regiones anotadas.
- Devuelve las etiquetas reales (`y_true`), las predichas (`y_pred`) y la imagen combinada con ambas visualizaciones.
---

```py 
mostrar_resultado_visual(y_true, y_pred, imagen_combined)
```
- Muestra visualmente los resultados de clasificaci√≥n (reales vs predichos) y calcula la precisi√≥n global del modelo.

<div align="center">
  <img src="salidas/comparacion_real_predicha.jpg" width="80%">
</div>

Tal y como se observa en la imagen, la parte izquierda muestra la clasificaci√≥n real (seg√∫n las anotaciones del archivo CSV) y la parte derecha muestra la clasificaci√≥n predicha por el modelo.

Cada tipo de micropl√°stico est√° representado con un color diferente:
* üü• Fragmentos (FRA): contornos y etiquetas en rojo.
* üü© Pellets (PEL): contornos y etiquetas en verde.
* üü¶ Alquitr√°n (TAR): contornos y etiquetas en azul.

De esta forma, es posible comparar visualmente de un vistazo las predicciones y los aciertos.
En general, la mayor√≠a de los objetos coinciden correctamente entre ambas im√°genes, aunque se aprecian algunas discrepancias: 
- Algunos fragmentos rojos fueron clasificados err√≥neamente como pellets verdes, lo que coincide con la confusi√≥n detectada en la matriz de confusi√≥n.
- Las part√≠culas de alquitr√°n azul suelen estar correctamente clasificadas, aunque en ciertos casos con forma irregular o bordes difusos el modelo las confundi√≥ con fragmentos.
- La distribuci√≥n general de colores muestra una buena correspondencia global entre las clasificaciones reales y las predichas, lo que respalda el resultado cuantitativo obtenido (accuracy ‚âà 72 %).

---
```py 
mostrar_matriz_confusion(y_true, y_pred, clases)
```
- Genera un **heatmap de la matriz de confusi√≥n** con `Seaborn` para visualizar los aciertos y errores del clasificador.

La matriz de confusi√≥n es una herramienta que muestra, para cada clase real, c√≥mo el clasificador asign√≥ sus **predicciones**. En ella, cada **fila** representa las **etiquetas reales** y cada **columna** las **etiquetas predichas**.
De este modo, la matriz permite visualizar para cada clase el n√∫mero de muestras clasificadas correctamente (cuando la predicci√≥n coincide con la etiqueta real) y el n√∫mero de muestras clasificadas incorrectamente como pertenecientes a alguna de las otras clases.

La matriz de confusi√≥n obtenida es: 

<div align="center">
  <img src="salidas/matriz_confusion.jpg" width="50%">
</div>

Interpretaci√≥n:
- **Diagonal principal (37, 24, 9):** son los aciertos del modelo ‚Üí el objeto se clasific√≥ correctamente.  
- **Fuera de la diagonal:** representan errores de clasificaci√≥n (confusiones entre clases).  

#### üîç An√°lisis detallado
- La clase **FRA** (fragmentos) tuvo **37 aciertos**, pero fue confundida **7 veces con PEL** (pellets) y **3 veces con TAR** (tiras).  
  Esto sugiere que algunos fragmentos comparten **formas o colores similares a los pellets**, lo que genera confusi√≥n.
  
- La clase **PEL** tuvo un rendimiento s√≥lido (**24 aciertos**, 7 errores hacia FRA).  
  Nuevamente, la mayor confusi√≥n se da entre **FRA ‚Üî PEL**, lo que indica que ambas clases tienen **caracter√≠sticas geom√©tricas o crom√°ticas parecidas**.

- La clase **TAR** obtuvo **9 aciertos**, pero tambi√©n se confundi√≥ en **3 casos como FRA** y **2 como PEL**.  
  Al ser posiblemente m√°s oscura o de forma irregular, puede haberse interpretado err√≥neamente seg√∫n la iluminaci√≥n o textura.

En conjunto, el **patr√≥n de confusi√≥n dominante** es entre **fragmentos (FRA)** y **pellets (PEL)**, lo que sugiere que el modelo podr√≠a beneficiarse de:
- Aumentar el peso de las caracter√≠sticas **de color** (HSV).  
- A√±adir m√°s im√°genes de entrenamiento para ambos tipos.  
- Aplicar segmentaci√≥n m√°s precisa para evitar que fragmentos incompletos afecten el c√°lculo de caracter√≠sticas.  

Sin embargo, se intent√≥ cambiar el peso de las distintas caracter√≠sticas pero, el resultado obtenido era peor que este pues, a la vez que mejoraba un elemento en concreto, los otros dos empeoraban.

---

```py 
imprimir_metricas(y_true, y_pred)
```
Esta funci√≥n calcula las m√©tricas del clasificador:
| **M√©trica** | **Descripci√≥n** | **F√≥rmula** | **Valor (%)** |
|--------------|------------------|--------------|----------------|
| **Exactitud (Accuracy)** | Porcentaje total de clasificaciones correctas sobre todas las predicciones. | `Accuracy = (TP + TN) / (TP + TN + FP + FN)` | **72.16** |
| **Precisi√≥n (Precision)** | Qu√© tan precisas son las predicciones positivas (por clase). Indica el nivel de ‚Äúfalsos positivos‚Äù cometidos. | `Precision = TP / (TP + FP)` | **75.25** |
| **Sensibilidad (Recall)** | Mide la capacidad del modelo para detectar correctamente todos los objetos de una clase (minimiza los falsos negativos). | `Recall = TP / (TP + FN)` | **72.16** |
| **F1-Score** | Promedio arm√≥nico entre precisi√≥n y recall; balance entre exactitud y cobertura. | `F1 = 2 * (Precision * Recall) / (Precision + Recall)` | **73.67** |

> **Leyenda de t√©rminos:**  
> - **TP:** Verdaderos Positivos  
> - **TN:** Verdaderos Negativos  
> - **FP:** Falsos Positivos  
> - **FN:** Falsos Negativos  

### üìà Interpretaci√≥n de las m√©tricas
- El modelo logra un rendimiento moderado-alto, identificando correctamente alrededor del 72 % de los micropl√°sticos.
- La precisi√≥n del 75 % indica que la mayor√≠a de las predicciones son correctas, mientras que un recall similar muestra que el sistema detecta bien las clases, aunque a√∫n pierde algunos objetos.
- El F1-score de 73.67 % refleja un equilibrio adecuado entre precisi√≥n y cobertura.

En conjunto, los resultados son satisfactorios considerando la simplicidad del clasificador y la variabilidad visual de las muestras.


> Uso de la IA:
- Explicaci√≥n de algunas funciones de las librer√≠as OpenCV y MatplotLib
- Refactorizaci√≥n del c√≥digo para hacerlo modular
- Redacci√≥n y mejora de docstrings
- Estructura y redacci√≥n del Readme



